{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.8\n",
      "/public/workspace/ryrl/venvs/versions/3.12.8/torch/bin/python\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1999, 1037, 4920, 1999, 1996, 2598, 2045, 2973, 1037, 7570, 10322, 4183, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = 'In a hole in the ground there lived a hobbit.'\n",
    "tokenizer(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(sequence)['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Some weights of SwinBackbone were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized: ['swin.hidden_states_norms.stage1.bias', 'swin.hidden_states_norms.stage1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoBackbone\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "processor = AutoImageProcessor.from_pretrained('microsoft/swin-tiny-patch4-window7-224')\n",
    "model = AutoBackbone.from_pretrained('microsoft/swin-tiny-patch4-window7-224', out_indices=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[ 0.3138,  0.4337,  0.4851,  ..., -0.3541, -0.3369, -0.3541],\n",
       "          [ 0.3652,  0.4337,  0.4679,  ..., -0.3541, -0.3541, -0.3883],\n",
       "          [ 0.3138,  0.3994,  0.4166,  ..., -0.4568, -0.4226, -0.3883],\n",
       "          ...,\n",
       "          [ 1.9064,  1.7865,  1.6495,  ...,  1.6153,  1.4954,  1.4440],\n",
       "          [ 1.8722,  1.8037,  1.7523,  ...,  1.4098,  1.1358,  0.9817],\n",
       "          [ 1.8722,  1.7180,  1.7352,  ...,  0.1254, -0.1657, -0.4739]],\n",
       "\n",
       "         [[-1.6155, -1.6155, -1.6155,  ..., -1.7906, -1.7906, -1.8081],\n",
       "          [-1.5630, -1.5630, -1.5630,  ..., -1.7731, -1.7556, -1.7731],\n",
       "          [-1.6331, -1.5980, -1.5630,  ..., -1.8081, -1.7906, -1.7906],\n",
       "          ...,\n",
       "          [-0.3901, -0.5301, -0.6352,  ..., -0.7402, -0.8102, -0.8627],\n",
       "          [-0.3901, -0.4426, -0.5651,  ..., -0.8452, -1.0028, -1.0728],\n",
       "          [-0.4251, -0.5651, -0.5826,  ..., -1.4930, -1.5980, -1.7206]],\n",
       "\n",
       "         [[-0.7936, -0.6018, -0.6541,  ..., -1.2293, -1.1247, -1.1596],\n",
       "          [-0.8458, -0.7238, -0.6890,  ..., -1.2293, -1.1596, -1.2293],\n",
       "          [-0.7413, -0.6367, -0.6018,  ..., -1.2467, -1.2641, -1.2816],\n",
       "          ...,\n",
       "          [ 1.6814,  1.6640,  1.3851,  ...,  1.4374,  1.3154,  1.1759],\n",
       "          [ 1.6465,  1.4548,  1.5594,  ...,  1.1585,  0.9319,  0.7751],\n",
       "          [ 1.6988,  1.6988,  1.5594,  ..., -0.1487, -0.6715, -0.8981]]]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BackboneOutput(feature_maps=(tensor([[[[ 1.0064e+00,  6.3087e-01, -1.9434e-01,  ...,  3.4310e-01,\n",
       "            2.3735e-01,  1.6851e-01],\n",
       "          [ 1.1366e+00,  6.7725e-01, -2.6275e-02,  ..., -1.1405e-01,\n",
       "            6.0058e-01,  1.7787e-01],\n",
       "          [ 1.0791e+00,  5.6264e-01,  2.5349e-01,  ...,  2.9255e-01,\n",
       "            3.0649e-01,  6.1798e-01],\n",
       "          ...,\n",
       "          [ 5.0817e-01,  3.7973e-01, -7.7769e-01,  ..., -8.8343e-02,\n",
       "            5.2977e-02, -5.7092e-01],\n",
       "          [-3.7535e-01, -1.8946e-01, -3.2585e-01,  ..., -2.9201e-01,\n",
       "           -5.8429e-02,  1.2849e-01],\n",
       "          [ 2.5337e-01, -8.9120e-02,  3.7873e-01,  ..., -7.1851e-01,\n",
       "            1.3847e-01,  5.3692e-01]],\n",
       "\n",
       "         [[ 9.5971e-01,  9.7547e-01,  1.3414e+00,  ...,  8.0082e-01,\n",
       "            8.1081e-01,  7.8101e-01],\n",
       "          [ 7.9007e-01,  1.2079e+00,  1.1176e+00,  ...,  9.6235e-01,\n",
       "            6.2085e-01,  7.4454e-01],\n",
       "          [ 5.2195e-02,  9.7713e-01,  1.0464e+00,  ...,  7.8407e-01,\n",
       "            9.2501e-01,  7.9040e-01],\n",
       "          ...,\n",
       "          [ 1.5364e+00,  1.4474e+00,  1.3669e+00,  ...,  8.9157e-01,\n",
       "            1.3441e+00,  1.5203e+00],\n",
       "          [ 1.6571e+00,  1.5495e+00,  1.5782e+00,  ...,  5.1749e-01,\n",
       "            1.3361e+00,  1.4069e+00],\n",
       "          [ 1.6271e+00,  1.6741e+00,  1.5733e+00,  ...,  6.9749e-02,\n",
       "            5.9969e-01, -6.4649e-02]],\n",
       "\n",
       "         [[-1.0611e+00, -8.8618e-01, -9.2136e-01,  ..., -1.0067e+00,\n",
       "           -1.0897e+00, -1.3464e+00],\n",
       "          [-7.3551e-01, -1.3470e+00, -6.6860e-01,  ..., -1.3656e+00,\n",
       "           -9.6558e-01, -1.0946e+00],\n",
       "          [-1.0999e+00, -1.0913e+00, -7.0619e-01,  ..., -1.2244e+00,\n",
       "           -8.4158e-01, -1.8124e-01],\n",
       "          ...,\n",
       "          [-3.6143e-01, -4.4984e-01, -4.8815e-01,  ..., -1.7085e-01,\n",
       "           -7.2806e-01, -5.4693e-01],\n",
       "          [-1.0450e+00, -2.6562e-01, -7.3188e-01,  ..., -5.7306e-02,\n",
       "           -3.2417e-01, -1.3082e+00],\n",
       "          [-1.1873e+00, -4.3371e-01, -5.4503e-02,  ...,  1.2146e-01,\n",
       "           -1.6340e-01,  6.4927e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-6.7181e-01, -4.1788e-01, -4.9082e-01,  ..., -6.8329e-01,\n",
       "           -7.6303e-01, -1.1190e+00],\n",
       "          [-1.1031e+00, -5.4560e-01, -2.3726e-01,  ..., -8.4765e-01,\n",
       "           -7.6631e-01, -9.2620e-01],\n",
       "          [-1.4400e+00, -1.0097e+00, -6.4823e-01,  ..., -8.2203e-01,\n",
       "           -9.7641e-01, -1.2630e+00],\n",
       "          ...,\n",
       "          [-6.2639e-01, -7.3904e-01, -6.3977e-01,  ..., -1.1516e+00,\n",
       "           -1.6422e-01,  8.9247e-02],\n",
       "          [-1.9955e-01, -4.9461e-01, -7.8596e-01,  ..., -1.6575e+00,\n",
       "           -4.2794e-01, -4.2375e-01],\n",
       "          [-5.8624e-01, -1.1882e-01, -4.6758e-01,  ..., -2.0037e+00,\n",
       "           -1.3892e+00, -9.4938e-01]],\n",
       "\n",
       "         [[ 1.4773e+00,  1.2951e+00,  1.3265e+00,  ...,  1.4276e+00,\n",
       "            1.3049e+00,  1.2771e+00],\n",
       "          [ 1.2810e+00,  1.3507e+00,  1.3210e+00,  ...,  1.4253e+00,\n",
       "            1.1915e+00,  1.1442e+00],\n",
       "          [ 1.2527e+00,  1.2587e+00,  1.2366e+00,  ...,  1.2962e+00,\n",
       "            1.3330e+00,  1.3172e+00],\n",
       "          ...,\n",
       "          [ 5.9953e-01,  8.2859e-01,  9.2873e-01,  ...,  7.0422e-01,\n",
       "            3.7539e-01,  6.5606e-01],\n",
       "          [ 6.9176e-01,  4.9668e-01,  8.5061e-01,  ...,  7.1650e-01,\n",
       "            5.0627e-01,  4.6261e-01],\n",
       "          [ 6.7759e-01,  6.5011e-01,  5.5478e-01,  ...,  6.3098e-01,\n",
       "            4.0490e-01,  5.6926e-01]],\n",
       "\n",
       "         [[-6.0317e-01, -5.0964e-01, -1.4120e-01,  ..., -1.1828e-01,\n",
       "            2.1837e-02,  1.5310e-03],\n",
       "          [-9.5323e-01, -2.1130e-01, -2.8068e-01,  ..., -3.3612e-02,\n",
       "           -4.1401e-01, -3.6642e-01],\n",
       "          [-1.6695e+00, -9.9313e-01, -9.9955e-01,  ..., -4.1771e-01,\n",
       "           -1.1368e+00, -7.1428e-01],\n",
       "          ...,\n",
       "          [-3.7443e-01, -1.0206e+00,  6.1265e-02,  ..., -2.1655e-01,\n",
       "           -1.8866e-01, -3.9789e-02],\n",
       "          [-1.7580e-01, -2.1298e-01, -8.6712e-01,  ...,  8.2015e-02,\n",
       "           -1.7756e-01, -6.6991e-01],\n",
       "          [-7.7687e-01,  3.8001e-03, -4.6250e-01,  ..., -4.4390e-01,\n",
       "           -1.3550e+00, -1.3301e+00]]]], grad_fn=<CloneBackward0>),), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 1.0064e+00,  6.3087e-01, -1.9434e-01,  ...,  3.4310e-01,\n",
       "             2.3735e-01,  1.6851e-01],\n",
       "           [ 1.1366e+00,  6.7725e-01, -2.6275e-02,  ..., -1.1405e-01,\n",
       "             6.0058e-01,  1.7787e-01],\n",
       "           [ 1.0791e+00,  5.6264e-01,  2.5349e-01,  ...,  2.9255e-01,\n",
       "             3.0649e-01,  6.1798e-01],\n",
       "           ...,\n",
       "           [ 5.0817e-01,  3.7973e-01, -7.7769e-01,  ..., -8.8343e-02,\n",
       "             5.2977e-02, -5.7092e-01],\n",
       "           [-3.7535e-01, -1.8946e-01, -3.2585e-01,  ..., -2.9201e-01,\n",
       "            -5.8429e-02,  1.2849e-01],\n",
       "           [ 2.5337e-01, -8.9120e-02,  3.7873e-01,  ..., -7.1851e-01,\n",
       "             1.3847e-01,  5.3692e-01]],\n",
       " \n",
       "          [[ 9.5971e-01,  9.7547e-01,  1.3414e+00,  ...,  8.0082e-01,\n",
       "             8.1081e-01,  7.8101e-01],\n",
       "           [ 7.9007e-01,  1.2079e+00,  1.1176e+00,  ...,  9.6235e-01,\n",
       "             6.2085e-01,  7.4454e-01],\n",
       "           [ 5.2195e-02,  9.7713e-01,  1.0464e+00,  ...,  7.8407e-01,\n",
       "             9.2501e-01,  7.9040e-01],\n",
       "           ...,\n",
       "           [ 1.5364e+00,  1.4474e+00,  1.3669e+00,  ...,  8.9157e-01,\n",
       "             1.3441e+00,  1.5203e+00],\n",
       "           [ 1.6571e+00,  1.5495e+00,  1.5782e+00,  ...,  5.1749e-01,\n",
       "             1.3361e+00,  1.4069e+00],\n",
       "           [ 1.6271e+00,  1.6741e+00,  1.5733e+00,  ...,  6.9749e-02,\n",
       "             5.9969e-01, -6.4649e-02]],\n",
       " \n",
       "          [[-1.0611e+00, -8.8618e-01, -9.2136e-01,  ..., -1.0067e+00,\n",
       "            -1.0897e+00, -1.3464e+00],\n",
       "           [-7.3551e-01, -1.3470e+00, -6.6860e-01,  ..., -1.3656e+00,\n",
       "            -9.6558e-01, -1.0946e+00],\n",
       "           [-1.0999e+00, -1.0913e+00, -7.0619e-01,  ..., -1.2244e+00,\n",
       "            -8.4158e-01, -1.8124e-01],\n",
       "           ...,\n",
       "           [-3.6143e-01, -4.4984e-01, -4.8815e-01,  ..., -1.7085e-01,\n",
       "            -7.2806e-01, -5.4693e-01],\n",
       "           [-1.0450e+00, -2.6562e-01, -7.3188e-01,  ..., -5.7306e-02,\n",
       "            -3.2417e-01, -1.3082e+00],\n",
       "           [-1.1873e+00, -4.3371e-01, -5.4503e-02,  ...,  1.2146e-01,\n",
       "            -1.6340e-01,  6.4927e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-6.7181e-01, -4.1788e-01, -4.9082e-01,  ..., -6.8329e-01,\n",
       "            -7.6303e-01, -1.1190e+00],\n",
       "           [-1.1031e+00, -5.4560e-01, -2.3726e-01,  ..., -8.4765e-01,\n",
       "            -7.6631e-01, -9.2620e-01],\n",
       "           [-1.4400e+00, -1.0097e+00, -6.4823e-01,  ..., -8.2203e-01,\n",
       "            -9.7641e-01, -1.2630e+00],\n",
       "           ...,\n",
       "           [-6.2639e-01, -7.3904e-01, -6.3977e-01,  ..., -1.1516e+00,\n",
       "            -1.6422e-01,  8.9247e-02],\n",
       "           [-1.9955e-01, -4.9461e-01, -7.8596e-01,  ..., -1.6575e+00,\n",
       "            -4.2794e-01, -4.2375e-01],\n",
       "           [-5.8624e-01, -1.1882e-01, -4.6758e-01,  ..., -2.0037e+00,\n",
       "            -1.3892e+00, -9.4938e-01]],\n",
       " \n",
       "          [[ 1.4773e+00,  1.2951e+00,  1.3265e+00,  ...,  1.4276e+00,\n",
       "             1.3049e+00,  1.2771e+00],\n",
       "           [ 1.2810e+00,  1.3507e+00,  1.3210e+00,  ...,  1.4253e+00,\n",
       "             1.1915e+00,  1.1442e+00],\n",
       "           [ 1.2527e+00,  1.2587e+00,  1.2366e+00,  ...,  1.2962e+00,\n",
       "             1.3330e+00,  1.3172e+00],\n",
       "           ...,\n",
       "           [ 5.9953e-01,  8.2859e-01,  9.2873e-01,  ...,  7.0422e-01,\n",
       "             3.7539e-01,  6.5606e-01],\n",
       "           [ 6.9176e-01,  4.9668e-01,  8.5061e-01,  ...,  7.1650e-01,\n",
       "             5.0627e-01,  4.6261e-01],\n",
       "           [ 6.7759e-01,  6.5011e-01,  5.5478e-01,  ...,  6.3098e-01,\n",
       "             4.0490e-01,  5.6926e-01]],\n",
       " \n",
       "          [[-6.0317e-01, -5.0964e-01, -1.4120e-01,  ..., -1.1828e-01,\n",
       "             2.1837e-02,  1.5310e-03],\n",
       "           [-9.5323e-01, -2.1130e-01, -2.8068e-01,  ..., -3.3612e-02,\n",
       "            -4.1401e-01, -3.6642e-01],\n",
       "           [-1.6695e+00, -9.9313e-01, -9.9955e-01,  ..., -4.1771e-01,\n",
       "            -1.1368e+00, -7.1428e-01],\n",
       "           ...,\n",
       "           [-3.7443e-01, -1.0206e+00,  6.1265e-02,  ..., -2.1655e-01,\n",
       "            -1.8866e-01, -3.9789e-02],\n",
       "           [-1.7580e-01, -2.1298e-01, -8.6712e-01,  ...,  8.2015e-02,\n",
       "            -1.7756e-01, -6.6991e-01],\n",
       "           [-7.7687e-01,  3.8001e-03, -4.6250e-01,  ..., -4.4390e-01,\n",
       "            -1.3550e+00, -1.3301e+00]]]], grad_fn=<CloneBackward0>),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_maps = outputs.feature_maps\n",
    "features_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained('ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "processor = AutoProcessor.from_pretrained('microsoft/layoutlmv2-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ 0.0402, -0.1029]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification  # classification for the whole sequence\n",
    "\n",
    "model = 'distilbert/distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model, torch_dtype='auto')\n",
    "\n",
    "sequence = 'In a hole in the ground there lived a hobbit.'\n",
    "inputs = tokenizer(sequence, return_tensors='pt')\n",
    "model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TokenClassifierOutput(loss=None, logits=tensor([[[ 0.0411, -0.2326],\n",
       "         [ 0.0410, -0.2950],\n",
       "         [-0.1394, -0.4368],\n",
       "         [-0.0520, -0.0561],\n",
       "         [-0.1129, -0.3613],\n",
       "         [-0.2915, -0.4180],\n",
       "         [ 0.0086, -0.3017],\n",
       "         [ 0.1891, -0.3631],\n",
       "         [ 0.1785, -0.3699],\n",
       "         [-0.1435, -0.2225],\n",
       "         [-0.0167,  0.0536],\n",
       "         [-0.3296, -0.2335],\n",
       "         [-0.1238, -0.1657],\n",
       "         [-0.5961, -0.4063],\n",
       "         [-0.7017, -0.2475]]], grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification # classification for each token of a squence\n",
    "\n",
    "model = 'distilbert/distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model, torch_dtype='auto')\n",
    "\n",
    "sequence = 'In a hole in the ground there lived a hobbit.'\n",
    "inputs = tokenizer(sequence, return_tensors='pt')\n",
    "model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WorkFlow:\n",
    "1. Get Tokenizer\n",
    "2. Get Model\n",
    "3. Get Tensor of the target\n",
    "4. Prediction of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
